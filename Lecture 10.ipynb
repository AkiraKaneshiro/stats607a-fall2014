{
 "metadata": {
  "name": "",
  "signature": "sha256:51116243ebc5d803f5d52e6309ba6ccc4b32559b1d6e81e5dcd9dc6045f9369e"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Today we'll cover:\n",
      "\n",
      "1. [Reading and writing text](#Reading-and-writing-text)\n",
      "2. [Reading from databases](#Reading-from-databases)\n",
      "3. [Reading from web APIs](#Reading-from-web-APIs)"
     ]
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Reading and writing text"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The 2 main reading & writing functions in pandas we will discuss are:\n",
      "\n",
      "* `read_csv()` to read comma separated data (we saw this in the last lecture)\n",
      "* `to_csv()` to write comnna separated data\n",
      "\n",
      "But before we get into the details of these, let us create some data files first."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pandas as pd"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df = pd.DataFrame([['German', 1777, 1855],\n",
      "                   ['Swiss', 1707, 1783],\n",
      "                   ['French', 1736, 1813],\n",
      "                   ['French', 1749, 1827]],\n",
      "                  index=['Gauss', 'Euler', 'Lagrange', 'Laplace'],\n",
      "                  columns=['Nationality', 'Born', 'Died'])\n",
      "df.index.name = 'Mathematician'\n",
      "df"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>Nationality</th>\n",
        "      <th>Born</th>\n",
        "      <th>Died</th>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>Mathematician</th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>Gauss</th>\n",
        "      <td> German</td>\n",
        "      <td> 1777</td>\n",
        "      <td> 1855</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>Euler</th>\n",
        "      <td>  Swiss</td>\n",
        "      <td> 1707</td>\n",
        "      <td> 1783</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>Lagrange</th>\n",
        "      <td> French</td>\n",
        "      <td> 1736</td>\n",
        "      <td> 1813</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>Laplace</th>\n",
        "      <td> French</td>\n",
        "      <td> 1749</td>\n",
        "      <td> 1827</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 2,
       "text": [
        "              Nationality  Born  Died\n",
        "Mathematician                        \n",
        "Gauss              German  1777  1855\n",
        "Euler               Swiss  1707  1783\n",
        "Lagrange           French  1736  1813\n",
        "Laplace            French  1749  1827"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df.to_csv('math.csv')  # export to a csv file"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!cat math.csv  # run shell command to examine file"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Mathematician,Nationality,Born,Died\r\n",
        "Gauss,German,1777,1855\r\n",
        "Euler,Swiss,1707,1783\r\n",
        "Lagrange,French,1736,1813\r\n",
        "Laplace,French,1749,1827\r\n"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "del df  # delete the DataFrame\n",
      "df = pd.read_csv('math.csv')  # read it back in\n",
      "df"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>Mathematician</th>\n",
        "      <th>Nationality</th>\n",
        "      <th>Born</th>\n",
        "      <th>Died</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0</th>\n",
        "      <td>    Gauss</td>\n",
        "      <td> German</td>\n",
        "      <td> 1777</td>\n",
        "      <td> 1855</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1</th>\n",
        "      <td>    Euler</td>\n",
        "      <td>  Swiss</td>\n",
        "      <td> 1707</td>\n",
        "      <td> 1783</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2</th>\n",
        "      <td> Lagrange</td>\n",
        "      <td> French</td>\n",
        "      <td> 1736</td>\n",
        "      <td> 1813</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>3</th>\n",
        "      <td>  Laplace</td>\n",
        "      <td> French</td>\n",
        "      <td> 1749</td>\n",
        "      <td> 1827</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 5,
       "text": [
        "  Mathematician Nationality  Born  Died\n",
        "0         Gauss      German  1777  1855\n",
        "1         Euler       Swiss  1707  1783\n",
        "2      Lagrange      French  1736  1813\n",
        "3       Laplace      French  1749  1827"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "That didn't quite give our original DataFrame back. We need to tell `read_csv` to use the first column (column 0) as the index."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df = pd.read_csv('math.csv', index_col=0)  # use columns 0 as index\n",
      "df"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>Nationality</th>\n",
        "      <th>Born</th>\n",
        "      <th>Died</th>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>Mathematician</th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>Gauss</th>\n",
        "      <td> German</td>\n",
        "      <td> 1777</td>\n",
        "      <td> 1855</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>Euler</th>\n",
        "      <td>  Swiss</td>\n",
        "      <td> 1707</td>\n",
        "      <td> 1783</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>Lagrange</th>\n",
        "      <td> French</td>\n",
        "      <td> 1736</td>\n",
        "      <td> 1813</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>Laplace</th>\n",
        "      <td> French</td>\n",
        "      <td> 1749</td>\n",
        "      <td> 1827</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 6,
       "text": [
        "              Nationality  Born  Died\n",
        "Mathematician                        \n",
        "Gauss              German  1777  1855\n",
        "Euler               Swiss  1707  1783\n",
        "Lagrange           French  1736  1813\n",
        "Laplace            French  1749  1827"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We can also save a DataFrame without the header and index."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df.to_csv('math.csv', index=False, header=False)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!cat math.csv"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "German,1777,1855\r\n",
        "Swiss,1707,1783\r\n",
        "French,1736,1813\r\n",
        "French,1749,1827\r\n"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df = pd.read_csv('math.csv', names=['Nationality', 'Born', 'Died'])  # read and supply columns names\n",
      "df.index = ['Gauss', 'Euler', 'Lagrange', 'Laplace']   # supply the index\n",
      "df.index.name = 'Mathematicians'\n",
      "df"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>Nationality</th>\n",
        "      <th>Born</th>\n",
        "      <th>Died</th>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>Mathematicians</th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>Gauss</th>\n",
        "      <td> German</td>\n",
        "      <td> 1777</td>\n",
        "      <td> 1855</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>Euler</th>\n",
        "      <td>  Swiss</td>\n",
        "      <td> 1707</td>\n",
        "      <td> 1783</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>Lagrange</th>\n",
        "      <td> French</td>\n",
        "      <td> 1736</td>\n",
        "      <td> 1813</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>Laplace</th>\n",
        "      <td> French</td>\n",
        "      <td> 1749</td>\n",
        "      <td> 1827</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 9,
       "text": [
        "               Nationality  Born  Died\n",
        "Mathematicians                        \n",
        "Gauss               German  1777  1855\n",
        "Euler                Swiss  1707  1783\n",
        "Lagrange            French  1736  1813\n",
        "Laplace             French  1749  1827"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "For large files, it might make sense to read them in chunks."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df.to_csv('math.csv')  # save again for index and header\n",
      "chunks = pd.read_csv('math.csv', chunksize=1)  # chunksize is in no. of lines\n",
      "french_count = 0\n",
      "for piece in chunks:\n",
      "    french_count += piece['Nationality'][0] == 'French'\n",
      "print 'Found %d French mathematicians.' % french_count"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Found 2 French mathematicians.\n"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import sys\n",
      "df.to_csv(sys.stdout, sep=':')  # can use a separator other than comma"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Mathematicians:Nationality:Born:Died\n",
        "Gauss:German:1777:1855\n",
        "Euler:Swiss:1707:1783\n",
        "Lagrange:French:1736:1813\n",
        "Laplace:French:1749:1827\n"
       ]
      }
     ],
     "prompt_number": 11
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Reading from databases"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Often the data you want to work with resides in a [relational database management system](http://en.wikipedia.org/wiki/Relational_database_management_system) (RDBMS). Some common commerical RDBMS implementations are: Oracle Database, Microsoft SQL server, MySQL and IBM DB2. [SQLite](http://www.sqlite.org/) is a freely available lightweight, disk-based (doesn't require a database server) database engine. In python, the package `sqlite3` provides an interface to SQLite.\n",
      "\n",
      "SQL (Structured Query Language) is a language used to interact with a database. A quick introduction to SQL can be found here:\n",
      "\n",
      "http://www.w3schools.com/sql/\n",
      "\n",
      "The SQL command to create a table in a database is `CREATE` (SQL queries are not case-sensitive: `CREATE` is the same as `create`)."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import sqlite3\n",
      "\n",
      "query = \"\"\"\n",
      "CREATE TABLE math\n",
      "(Mathematician VARCHAR(10),\n",
      " Nationality VARCHAR(10),\n",
      " Born INTEGER,\n",
      " Died INTEGER\n",
      ");\"\"\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 12
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now that we have created our first query, let us connect to a database and execute the query. In SQLite, databases are stored on disk as files. However, we can create an in-memory database denoted by the special name `:memory:`.\n",
      "\n",
      "Any query that changes the database, need to be committed to ensure that the change is visible to other connections to the database that might be open at the same time."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "con = sqlite3.connect(':memory:')  # connect to an in-memory database\n",
      "con.execute(query)  # execute the query\n",
      "con.commit()  # commit the change"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 13
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We now have an empty table in the `:memory:` database. Let us insert some values into it using the SQL command `INSERT`."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "con.execute(\"INSERT INTO math VALUES('Gauss', 'German', 1777, 1855)\")  # insert values\n",
      "con.commit()  # and commit"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 14
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "At this stage, the table has a single row in it. Let us retrieve contents of the table using the SQL command `SELECT`. The result of executing a `SELECT` command is a *cursor*. You can think of it as an iterator."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cursor = con.execute('SELECT * FROM math')\n",
      "for row in cursor:\n",
      "    print row"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(u'Gauss', u'German', 1777, 1855)\n"
       ]
      }
     ],
     "prompt_number": 15
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Let us insert some more values in our table. The `executemany` method is useful for executing many commands for the same type. The placeholder `?` gets replaces by the values supplied in the list argument."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "values = [('Euler', 'Swiss', 1707, 1783),\n",
      "          ('Lagrange', 'French', 1736, 1813),\n",
      "          ('Laplace', 'French', 1749, 1827)]\n",
      "con.executemany(\"INSERT INTO math VALUES(?, ?, ?, ?)\", values)\n",
      "con.commit()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 16
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We have seen that a cursor can be used an iterators. If you want one row, you can use the `fetchone()` method. If you you want all rows, you can use the `fetchall()` method."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cursor = con.execute('SELECT * FROM math')\n",
      "print \"Fetching one row...\"\n",
      "print cursor.fetchone()\n",
      "print \"Fetching all remaining rows...\"\n",
      "print cursor.fetchall()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Fetching one row...\n",
        "(u'Gauss', u'German', 1777, 1855)\n",
        "Fetching all remaining rows...\n",
        "[(u'Euler', u'Swiss', 1707, 1783), (u'Lagrange', u'French', 1736, 1813), (u'Laplace', u'French', 1749, 1827)]\n"
       ]
      }
     ],
     "prompt_number": 17
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Pandas provides a convenient way to convert results of SQL queries in DataFrame objects."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pandas.io.sql as sql\n",
      "sql.read_sql('SELECT * FROM math', con)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>Mathematician</th>\n",
        "      <th>Nationality</th>\n",
        "      <th>Born</th>\n",
        "      <th>Died</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0</th>\n",
        "      <td>    Gauss</td>\n",
        "      <td> German</td>\n",
        "      <td> 1777</td>\n",
        "      <td> 1855</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1</th>\n",
        "      <td>    Euler</td>\n",
        "      <td>  Swiss</td>\n",
        "      <td> 1707</td>\n",
        "      <td> 1783</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2</th>\n",
        "      <td> Lagrange</td>\n",
        "      <td> French</td>\n",
        "      <td> 1736</td>\n",
        "      <td> 1813</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>3</th>\n",
        "      <td>  Laplace</td>\n",
        "      <td> French</td>\n",
        "      <td> 1749</td>\n",
        "      <td> 1827</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 18,
       "text": [
        "  Mathematician Nationality  Born  Died\n",
        "0         Gauss      German  1777  1855\n",
        "1         Euler       Swiss  1707  1783\n",
        "2      Lagrange      French  1736  1813\n",
        "3       Laplace      French  1749  1827"
       ]
      }
     ],
     "prompt_number": 18
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Let us try retrieving only French mathematicians."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sql.read_sql('SELECT * FROM math WHERE Nationality=\"French\"', con)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>Mathematician</th>\n",
        "      <th>Nationality</th>\n",
        "      <th>Born</th>\n",
        "      <th>Died</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0</th>\n",
        "      <td> Lagrange</td>\n",
        "      <td> French</td>\n",
        "      <td> 1736</td>\n",
        "      <td> 1813</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1</th>\n",
        "      <td>  Laplace</td>\n",
        "      <td> French</td>\n",
        "      <td> 1749</td>\n",
        "      <td> 1827</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 19,
       "text": [
        "  Mathematician Nationality  Born  Died\n",
        "0      Lagrange      French  1736  1813\n",
        "1       Laplace      French  1749  1827"
       ]
      }
     ],
     "prompt_number": 19
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Reading from web APIs"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We will use the [Twitter Search API](https://dev.twitter.com/rest/public/search) to search for tweets. The API returns results in the [JSON format](http://en.wikipedia.org/wiki/JSON). You will remember that IPython notebooks (such as this document!) are also encoded in the JSON format.\n",
      "\n",
      "But before we can build a search query and execute it on twitter, we need to authenticate. We will use Twitter's [Application-only authentication](https://dev.twitter.com/oauth/application-only). The way this works is:\n",
      "\n",
      "1. Our (Python) application will encodes its *consumer key* and *consumer secret* into a specially encoded set of credentials.\n",
      "2. Then the application will make a request to exchange these credentials for a *bearer token*.\n",
      "3. When accessing the API, our application will use the *bearer token* to authenticate.\n",
      "\n",
      "Let us work on Step 1."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from urllib2 import urlopen, Request  # to create HTTP requests and open URLs\n",
      "import base64  # for base64 encoding\n",
      "import json  # for handling the JSON format\n",
      "\n",
      "consumer_key = 'dNcn9ZjPJ6dSaXJMYnVgna7jg'  # our app's consumer key\n",
      "consumer_secret = open('consumer_secret', 'r').read().strip()  # read secret (should not be made public) from file\n",
      "\n",
      "bearer_token = '%s:%s' % (consumer_key, consumer_secret)\n",
      "encoded_bearer_token = base64.b64encode(bearer_token.encode('ascii'))  # bearer token needs to be base64 encoded\n",
      "request = Request('https://api.twitter.com/oauth2/token')\n",
      "request.add_header('Content-Type',\n",
      "                   'application/x-www-form-urlencoded;charset=UTF-8')\n",
      "request.add_header('Authorization',\n",
      "                   'Basic %s' % encoded_bearer_token.decode('utf-8'))\n",
      "request_data = 'grant_type=client_credentials'.encode('ascii')\n",
      "request.add_data(request_data)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 20
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now that we have a Request object ready, let us send our request to get a bearer token to Twitter (Step 2)."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "response = urlopen(request)  # make the request\n",
      "raw_data = response.read().decode('utf-8')  # read the raw results in JSON format\n",
      "data = json.loads(raw_data)  # decode JSON into Python data structures\n",
      "bearer_token = data['access_token']  # extract the token"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 21
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We can now use the bearer token to search (Step 3). Let us search for tweets containing \"data science\"."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "url = 'https://api.twitter.com/1.1/search/tweets.json?q=data%20science'  # search for \"data science\"\n",
      "request = Request(url)\n",
      "request.add_header('Authorization', 'Bearer %s' % bearer_token)  # use the bearer token from Step 2\n",
      "response = urlopen(request)  # make the request\n",
      "raw_data = response.read().decode('utf-8')  # results in raw JSON\n",
      "data = json.loads(raw_data)  # decode JSON into Python data structures"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 22
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "At this point `data` is a dictionary with just two keys: `search_metadata` and `statuses`. The latter has the tweets inside a Python list."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print data.keys()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[u'search_metadata', u'statuses']\n"
       ]
      }
     ],
     "prompt_number": 23
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print data['statuses'][0]  # get the first tweet, it is returned as a dict"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "{u'contributors': None, u'truncated': False, u'text': u'RT @digiphile: Context for #CIMAevents on data journalism: reports from @TowCenter: http://t.co/rcVOLQkFJg @CIMA_Media: http://t.co/vvNHyWa\\u2026', u'in_reply_to_status_id': None, u'id': 522428608170983425, u'favorite_count': 0, u'source': u'<a href=\"http://twitter.com\" rel=\"nofollow\">Twitter Web Client</a>', u'retweeted': False, u'coordinates': None, u'entities': {u'symbols': [], u'user_mentions': [{u'id': 1175221, u'indices': [3, 13], u'id_str': u'1175221', u'screen_name': u'digiphile', u'name': u'Alex Howard'}, {u'id': 373566331, u'indices': [72, 82], u'id_str': u'373566331', u'screen_name': u'TowCenter', u'name': u'Tow Center '}, {u'id': 87728073, u'indices': [107, 118], u'id_str': u'87728073', u'screen_name': u'CIMA_Media', u'name': u'CIMA'}], u'hashtags': [{u'indices': [27, 38], u'text': u'CIMAevents'}, {u'indices': [139, 140], u'text': u'ddj'}], u'urls': [{u'url': u'http://t.co/rcVOLQkFJg', u'indices': [84, 106], u'expanded_url': u'http://towcenter.org/art-science-data-driven-journalism/', u'display_url': u'towcenter.org/art-science-da\\u2026'}, {u'url': u'http://t.co/vvNHyWaNOr', u'indices': [139, 140], u'expanded_url': u'http://cima.ned.org/publications/understanding-data-can-news-media-rise-challenge', u'display_url': u'cima.ned.org/publications/u\\u2026'}]}, u'in_reply_to_screen_name': None, u'in_reply_to_user_id': None, u'retweet_count': 4, u'id_str': u'522428608170983425', u'favorited': False, u'retweeted_status': {u'contributors': None, u'truncated': False, u'text': u'Context for #CIMAevents on data journalism: reports from @TowCenter: http://t.co/rcVOLQkFJg @CIMA_Media: http://t.co/vvNHyWaNOr #ddj', u'in_reply_to_status_id': None, u'id': 522427548064813056, u'favorite_count': 1, u'source': u'<a href=\"https://about.twitter.com/products/tweetdeck\" rel=\"nofollow\">TweetDeck</a>', u'retweeted': False, u'coordinates': None, u'entities': {u'symbols': [], u'user_mentions': [{u'id': 373566331, u'indices': [57, 67], u'id_str': u'373566331', u'screen_name': u'TowCenter', u'name': u'Tow Center '}, {u'id': 87728073, u'indices': [92, 103], u'id_str': u'87728073', u'screen_name': u'CIMA_Media', u'name': u'CIMA'}], u'hashtags': [{u'indices': [12, 23], u'text': u'CIMAevents'}, {u'indices': [128, 132], u'text': u'ddj'}], u'urls': [{u'url': u'http://t.co/rcVOLQkFJg', u'indices': [69, 91], u'expanded_url': u'http://towcenter.org/art-science-data-driven-journalism/', u'display_url': u'towcenter.org/art-science-da\\u2026'}, {u'url': u'http://t.co/vvNHyWaNOr', u'indices': [105, 127], u'expanded_url': u'http://cima.ned.org/publications/understanding-data-can-news-media-rise-challenge', u'display_url': u'cima.ned.org/publications/u\\u2026'}]}, u'in_reply_to_screen_name': None, u'in_reply_to_user_id': None, u'retweet_count': 4, u'id_str': u'522427548064813056', u'favorited': False, u'user': {u'follow_request_sent': None, u'profile_use_background_image': True, u'profile_text_color': u'333333', u'default_profile_image': False, u'id': 1175221, u'profile_background_image_url_https': u'https://pbs.twimg.com/profile_background_images/336302576/MLK-memorial-silhouettes.jpg', u'verified': False, u'profile_location': None, u'profile_image_url_https': u'https://pbs.twimg.com/profile_images/467136413092151296/4m6R9jR-_normal.jpeg', u'profile_sidebar_fill_color': u'C0DFEC', u'entities': {u'url': {u'urls': [{u'url': u'http://t.co/d6y06PVuiv', u'indices': [0, 22], u'expanded_url': u'http://e-pluribusunum.com/about', u'display_url': u'e-pluribusunum.com/about'}]}, u'description': {u'urls': [{u'url': u'http://t.co/IFBZkS9S0D', u'indices': [100, 122], u'expanded_url': u'http://tek.io/1nPpOsv', u'display_url': u'tek.io/1nPpOsv'}, {u'url': u'http://t.co/KeO74DLium', u'indices': [135, 157], u'expanded_url': u'http://j.mp/ContactABH', u'display_url': u'j.mp/ContactABH'}]}}, u'followers_count': 218422, u'profile_sidebar_border_color': u'A8C7F7', u'id_str': u'1175221', u'profile_background_color': u'022330', u'listed_count': 4613, u'is_translation_enabled': False, u'utc_offset': -14400, u'statuses_count': 108676, u'description': u'Father, husband, analyst, citizen, cyclist, chef. Editor, @ePluribusUnum. Columnist, @TechRepublic: http://t.co/IFBZkS9S0D Contact me: http://t.co/KeO74DLium', u'friends_count': 1244, u'location': u'Washington, DC', u'profile_link_color': u'002491', u'profile_image_url': u'http://pbs.twimg.com/profile_images/467136413092151296/4m6R9jR-_normal.jpeg', u'following': None, u'geo_enabled': True, u'profile_banner_url': u'https://pbs.twimg.com/profile_banners/1175221/1412465990', u'profile_background_image_url': u'http://pbs.twimg.com/profile_background_images/336302576/MLK-memorial-silhouettes.jpg', u'name': u'Alex Howard', u'lang': u'en', u'profile_background_tile': True, u'favourites_count': 35007, u'screen_name': u'digiphile', u'notifications': None, u'url': u'http://t.co/d6y06PVuiv', u'created_at': u'Wed Mar 14 19:12:20 +0000 2007', u'contributors_enabled': False, u'time_zone': u'Eastern Time (US & Canada)', u'protected': False, u'default_profile': False, u'is_translator': False}, u'geo': None, u'in_reply_to_user_id_str': None, u'possibly_sensitive': False, u'lang': u'en', u'created_at': u'Wed Oct 15 16:43:28 +0000 2014', u'in_reply_to_status_id_str': None, u'place': None, u'metadata': {u'iso_language_code': u'en', u'result_type': u'recent'}}, u'user': {u'follow_request_sent': None, u'profile_use_background_image': True, u'profile_text_color': u'788038', u'default_profile_image': False, u'id': 19593365, u'profile_background_image_url_https': u'https://pbs.twimg.com/profile_background_images/86012198/Ada_lovelace.jpg', u'verified': False, u'profile_location': None, u'profile_image_url_https': u'https://pbs.twimg.com/profile_images/3434199120/858cad9cf33f3549980fd223a7c58c53_normal.jpeg', u'profile_sidebar_fill_color': u'99CC33', u'entities': {u'description': {u'urls': []}}, u'followers_count': 2111, u'profile_sidebar_border_color': u'FFFFFF', u'id_str': u'19593365', u'profile_background_color': u'173ED6', u'listed_count': 79, u'is_translation_enabled': False, u'utc_offset': 3600, u'statuses_count': 13787, u'description': u'Journalist, Lecturer, Researcher /London School of Journalism(LSJ)/ #vegan #datajournalism  @dagmedyanet Views expressed herearemy own.RTs not endorsement.', u'friends_count': 2282, u'location': u'London/Istanbul/San Francisco ', u'profile_link_color': u'275BD6', u'profile_image_url': u'http://pbs.twimg.com/profile_images/3434199120/858cad9cf33f3549980fd223a7c58c53_normal.jpeg', u'following': None, u'geo_enabled': True, u'profile_banner_url': u'https://pbs.twimg.com/profile_banners/19593365/1349899907', u'profile_background_image_url': u'http://pbs.twimg.com/profile_background_images/86012198/Ada_lovelace.jpg', u'name': u'Pinar Dag', u'lang': u'en', u'profile_background_tile': True, u'favourites_count': 4927, u'screen_name': u'pinardag', u'notifications': None, u'url': None, u'created_at': u'Tue Jan 27 14:16:33 +0000 2009', u'contributors_enabled': False, u'time_zone': u'London', u'protected': False, u'default_profile': False, u'is_translator': False}, u'geo': None, u'in_reply_to_user_id_str': None, u'possibly_sensitive': False, u'lang': u'en', u'created_at': u'Wed Oct 15 16:47:41 +0000 2014', u'in_reply_to_status_id_str': None, u'place': None, u'metadata': {u'iso_language_code': u'en', u'result_type': u'recent'}}\n"
       ]
      }
     ],
     "prompt_number": 24
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Extract the text and created_at fields and convert in pandas DataFrame\n",
      "tweets_df = pd.DataFrame(data['statuses'], columns=['created_at', 'text'])\n",
      "tweets_df"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>created_at</th>\n",
        "      <th>text</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0 </th>\n",
        "      <td> Wed Oct 15 16:47:41 +0000 2014</td>\n",
        "      <td> RT @digiphile: Context for #CIMAevents on data...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1 </th>\n",
        "      <td> Wed Oct 15 16:45:32 +0000 2014</td>\n",
        "      <td> Startup Crunches 100 Terabytes of Data in a Re...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2 </th>\n",
        "      <td> Wed Oct 15 16:45:17 +0000 2014</td>\n",
        "      <td> RT @digiphile: Context for #CIMAevents on data...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>3 </th>\n",
        "      <td> Wed Oct 15 16:45:04 +0000 2014</td>\n",
        "      <td>                            http://t.co/0SoF6iiyGj</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>4 </th>\n",
        "      <td> Wed Oct 15 16:45:01 +0000 2014</td>\n",
        "      <td> Could Chess ever be a big spectator sporting e...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>5 </th>\n",
        "      <td> Wed Oct 15 16:44:30 +0000 2014</td>\n",
        "      <td> RT @opentechmatt: \"Online tools for open scien...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>6 </th>\n",
        "      <td> Wed Oct 15 16:44:24 +0000 2014</td>\n",
        "      <td> RT @digiphile: Context for #CIMAevents on data...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>7 </th>\n",
        "      <td> Wed Oct 15 16:44:16 +0000 2014</td>\n",
        "      <td> RT @digiphile: Context for #CIMAevents on data...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>8 </th>\n",
        "      <td> Wed Oct 15 16:43:28 +0000 2014</td>\n",
        "      <td> Context for #CIMAevents on data journalism: re...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>9 </th>\n",
        "      <td> Wed Oct 15 16:41:06 +0000 2014</td>\n",
        "      <td> Cookie Science 7: Collecting good data means t...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>10</th>\n",
        "      <td> Wed Oct 15 16:40:23 +0000 2014</td>\n",
        "      <td> Will Salesforce's New Analytics Cloud Make Wav...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>11</th>\n",
        "      <td> Wed Oct 15 16:40:22 +0000 2014</td>\n",
        "      <td> Will Salesforce's New Analytics Cloud Make Wav...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>12</th>\n",
        "      <td> Wed Oct 15 16:40:21 +0000 2014</td>\n",
        "      <td> Will Salesforce's New Analytics Cloud Make Wav...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>13</th>\n",
        "      <td> Wed Oct 15 16:40:21 +0000 2014</td>\n",
        "      <td> Will Salesforce's New Analytics Cloud Make Wav...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>14</th>\n",
        "      <td> Wed Oct 15 16:40:20 +0000 2014</td>\n",
        "      <td> Will Salesforce's New Analytics Cloud Make Wav...</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 25,
       "text": [
        "                        created_at  \\\n",
        "0   Wed Oct 15 16:47:41 +0000 2014   \n",
        "1   Wed Oct 15 16:45:32 +0000 2014   \n",
        "2   Wed Oct 15 16:45:17 +0000 2014   \n",
        "3   Wed Oct 15 16:45:04 +0000 2014   \n",
        "4   Wed Oct 15 16:45:01 +0000 2014   \n",
        "5   Wed Oct 15 16:44:30 +0000 2014   \n",
        "6   Wed Oct 15 16:44:24 +0000 2014   \n",
        "7   Wed Oct 15 16:44:16 +0000 2014   \n",
        "8   Wed Oct 15 16:43:28 +0000 2014   \n",
        "9   Wed Oct 15 16:41:06 +0000 2014   \n",
        "10  Wed Oct 15 16:40:23 +0000 2014   \n",
        "11  Wed Oct 15 16:40:22 +0000 2014   \n",
        "12  Wed Oct 15 16:40:21 +0000 2014   \n",
        "13  Wed Oct 15 16:40:21 +0000 2014   \n",
        "14  Wed Oct 15 16:40:20 +0000 2014   \n",
        "\n",
        "                                                 text  \n",
        "0   RT @digiphile: Context for #CIMAevents on data...  \n",
        "1   Startup Crunches 100 Terabytes of Data in a Re...  \n",
        "2   RT @digiphile: Context for #CIMAevents on data...  \n",
        "3                              http://t.co/0SoF6iiyGj  \n",
        "4   Could Chess ever be a big spectator sporting e...  \n",
        "5   RT @opentechmatt: \"Online tools for open scien...  \n",
        "6   RT @digiphile: Context for #CIMAevents on data...  \n",
        "7   RT @digiphile: Context for #CIMAevents on data...  \n",
        "8   Context for #CIMAevents on data journalism: re...  \n",
        "9   Cookie Science 7: Collecting good data means t...  \n",
        "10  Will Salesforce's New Analytics Cloud Make Wav...  \n",
        "11  Will Salesforce's New Analytics Cloud Make Wav...  \n",
        "12  Will Salesforce's New Analytics Cloud Make Wav...  \n",
        "13  Will Salesforce's New Analytics Cloud Make Wav...  \n",
        "14  Will Salesforce's New Analytics Cloud Make Wav...  "
       ]
      }
     ],
     "prompt_number": 25
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "url = 'https://api.twitter.com/1.1/search/tweets.json?q=%23datascience'  # search for the hashtag #datascience\n",
      "request = Request(url)\n",
      "request.add_header('Authorization', 'Bearer %s' % bearer_token)  # use the bearer token from Step 2\n",
      "response = urlopen(request)  # make the request\n",
      "raw_data = response.read().decode('utf-8')  # results in raw JSON\n",
      "data = json.loads(raw_data)  # decode JSON into Python data structures\n",
      "hashtag_tweets_df = pd.DataFrame(data['statuses'], columns=['created_at', 'text'])\n",
      "hashtag_tweets_df"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>created_at</th>\n",
        "      <th>text</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0 </th>\n",
        "      <td> Wed Oct 15 16:43:58 +0000 2014</td>\n",
        "      <td> RT @GilPress: Most companies analyze a mere 12...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1 </th>\n",
        "      <td> Wed Oct 15 16:43:56 +0000 2014</td>\n",
        "      <td> RT@devonkirschmann: gotta love #datascience di...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2 </th>\n",
        "      <td> Wed Oct 15 16:40:00 +0000 2014</td>\n",
        "      <td> RT @tinagroves: @jeggers describes how, unlike...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>3 </th>\n",
        "      <td> Wed Oct 15 16:39:50 +0000 2014</td>\n",
        "      <td> RT @BigDataTechCon: Why Do We Need #DataScienc...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>4 </th>\n",
        "      <td> Wed Oct 15 16:39:37 +0000 2014</td>\n",
        "      <td> RT @devonkirschmann: gotta love #datascience #...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>5 </th>\n",
        "      <td> Wed Oct 15 16:38:32 +0000 2014</td>\n",
        "      <td> RT @lindz: RT@devonkirschmann: gotta love #dat...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>6 </th>\n",
        "      <td> Wed Oct 15 16:37:37 +0000 2014</td>\n",
        "      <td> RT@devonkirschmann: gotta love #datascience #d...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>7 </th>\n",
        "      <td> Wed Oct 15 16:36:52 +0000 2014</td>\n",
        "      <td> Good read RT @kleaf: Building better sales org...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>8 </th>\n",
        "      <td> Wed Oct 15 16:36:41 +0000 2014</td>\n",
        "      <td> RT @MDM_SDP: Disruption Coming For MDM  - http...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>9 </th>\n",
        "      <td> Wed Oct 15 16:35:48 +0000 2014</td>\n",
        "      <td>      RT @devonkirschmann: gotta love #datascience</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>10</th>\n",
        "      <td> Wed Oct 15 16:35:11 +0000 2014</td>\n",
        "      <td> Fledgling data science profession under strain...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>11</th>\n",
        "      <td> Wed Oct 15 16:32:51 +0000 2014</td>\n",
        "      <td>                           gotta love #datascience</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>12</th>\n",
        "      <td> Wed Oct 15 16:31:53 +0000 2014</td>\n",
        "      <td> RT @curtwehrley: Revolution R Open, an enhance...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>13</th>\n",
        "      <td> Wed Oct 15 16:31:42 +0000 2014</td>\n",
        "      <td> RT @RichBonneauNYU: looking forward to Thibaut...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>14</th>\n",
        "      <td> Wed Oct 15 16:30:12 +0000 2014</td>\n",
        "      <td> Where Will Healthcare's Data Scientists Find T...</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 26,
       "text": [
        "                        created_at  \\\n",
        "0   Wed Oct 15 16:43:58 +0000 2014   \n",
        "1   Wed Oct 15 16:43:56 +0000 2014   \n",
        "2   Wed Oct 15 16:40:00 +0000 2014   \n",
        "3   Wed Oct 15 16:39:50 +0000 2014   \n",
        "4   Wed Oct 15 16:39:37 +0000 2014   \n",
        "5   Wed Oct 15 16:38:32 +0000 2014   \n",
        "6   Wed Oct 15 16:37:37 +0000 2014   \n",
        "7   Wed Oct 15 16:36:52 +0000 2014   \n",
        "8   Wed Oct 15 16:36:41 +0000 2014   \n",
        "9   Wed Oct 15 16:35:48 +0000 2014   \n",
        "10  Wed Oct 15 16:35:11 +0000 2014   \n",
        "11  Wed Oct 15 16:32:51 +0000 2014   \n",
        "12  Wed Oct 15 16:31:53 +0000 2014   \n",
        "13  Wed Oct 15 16:31:42 +0000 2014   \n",
        "14  Wed Oct 15 16:30:12 +0000 2014   \n",
        "\n",
        "                                                 text  \n",
        "0   RT @GilPress: Most companies analyze a mere 12...  \n",
        "1   RT@devonkirschmann: gotta love #datascience di...  \n",
        "2   RT @tinagroves: @jeggers describes how, unlike...  \n",
        "3   RT @BigDataTechCon: Why Do We Need #DataScienc...  \n",
        "4   RT @devonkirschmann: gotta love #datascience #...  \n",
        "5   RT @lindz: RT@devonkirschmann: gotta love #dat...  \n",
        "6   RT@devonkirschmann: gotta love #datascience #d...  \n",
        "7   Good read RT @kleaf: Building better sales org...  \n",
        "8   RT @MDM_SDP: Disruption Coming For MDM  - http...  \n",
        "9        RT @devonkirschmann: gotta love #datascience  \n",
        "10  Fledgling data science profession under strain...  \n",
        "11                            gotta love #datascience  \n",
        "12  RT @curtwehrley: Revolution R Open, an enhance...  \n",
        "13  RT @RichBonneauNYU: looking forward to Thibaut...  \n",
        "14  Where Will Healthcare's Data Scientists Find T...  "
       ]
      }
     ],
     "prompt_number": 26
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# clean up temporary files in the end\n",
      "!rm math.csv"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 27
    }
   ],
   "metadata": {}
  }
 ]
}